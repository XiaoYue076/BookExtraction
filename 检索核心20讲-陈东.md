### 1.为什么需要学习检索？

在我看来，检索就是在海量的数据中，快速提取出最想要的东西。

此书中定义【检索技术：是更底层的通用技术，它研究的是如何将我们所需的数据高效地取出来】

了解和使用合适的检索技术，往往能有效提升整个程序的执行效率。

![image-20240327160438188](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240327160438188.png)

学好该技术的关键：

**夯实基础**：数组、链表、位图、布隆过滤器、哈希表、二叉树、跳表、倒排索引

**实践技术**：结合场景中的实际需求，从实践学习中落实自己的技术

**此处记一个问题：什么是双buffer机制？**——2024/3/27

【在业界实现索引更新的时候，为了追求更高的检索性能，一般不会直接对索引加锁，而是会利用“双buffer机制”来实现更新。但是像搜索引擎这样万亿级网页的索引规模，无法直接使用“双buffer机制”来更新，更需要“全量索引结合增量索引”方案来更新索引。】

回答：Double Buffer(双缓冲机制)：就是在内存里同时保存两份一样的索引，一个是索引A，一个是索引B。会使用一个指针p指向索引A，表示索引A是当前可访问的索引。那么用户在访问时就会通过指针p去访问索引A。若需要更新，指更新索引B即可。AB之间不存在读写竞争关系。更新完B后，将指针B通过原子操作从A直接切换到B上，此时把B当作“只读索引”,然后更新索引A。

​                                                                        ——2024/4/1

![image-20240327161245840](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240327161245840.png)

如何学习此书：

1.**多思考，多提问，善用“理解记忆法”**：多问自己几个为什么？

2.**建立自己的知识体系**：对比和拆解各种知识点，让彼此之间形成联系。

3.**有耐心、反复学、多交流**：真正掌握一项技能，反复学习是非常用必要的！

### 2.关于数组和链表

数组和链表分别代表了连续空间和不连续空间的最基础的存储方式，它们是线性表的典型代表。其他所有的数据结构，比如栈、队列、二叉树、B+树等，都是这二者的结合和变化。

【对于大规模数组，往往会通过二分查找法完成高效地检索。**检索的核心**：通过合理的组织数据，尽可能地快速减少查询的范围】

- 数组的“连续存储空间”带来了随机访问的特点。
- 链表的检索能力偏弱，但在动态调整上更容易：插入和删除。

高效改造链表：让链表的每个节点不再只是存储一个元素，而是存储一个小数组。

**思考题：**

1.对于有序数组的高效检索，为什么使用折半查找，而不是3-7分查找算法？

我的想法：折半查找，在最差情况下时间复杂度也是o(log(n)),并且折半查找更注重性能的平衡和稳定，波动较小。

**整理**：二分查找所需的信息量小:log（1/2）+log(1/2)远小于log(0.3)+log(0.7);

二分查找该类更加均匀，没有偏向任何一端，性能波动小，速度平稳；二分最大的好处是平衡，不会出现最差的情况。【信息量：信息量是指信息多少的量度。若信源有m种消息，且每个消息是以相等可能产生的，则该信源的信息量可表示为I=logm。】

2.给出两个查询值X和Y作为查询范围，如何操作才能找出大于X和小于Y的区间？

我的想法：对X和Y分别进行二分查找，并将两部分合二为一即可。

**整理：**分别用二分查找X和Y对应的下标，然后取中间的数据。

### 3.二叉搜索树和跳表

【二叉搜索树和跳表都能做到O（log n)的查询时间代价，还拥有灵活的调整能力，并且调整代价也是O（log n)（包括寻找插入位置的时间代价）】

二叉搜索树：它的左子树所有节点的值都小于根节点，同时右子树所有根节点的值都大于等于根节点。

尽管有序数组和二叉搜索树，在数据结构形态上看起来差异很大，但是在提高检索效率上，核心原理一致，即都是二分查找。

二叉搜索树的检索时间代价不一定是o(log n),**对于不平衡的二叉搜索树，**省去左节点，其本质也是一个单链表。它无法满足过滤“一半的数据”，因此无法缩小查询范围。

**为了提升检索效率，尽可能地保证二叉搜索树的平衡性。如AVL树（平衡二叉树）和红黑树，本质上都是二叉搜索树。**

链表访问中间节点效率低的原因是：每个节点只存储了下一个节点的指针，要沿着这个指针遍历每个后续节点才能达到中间节点。

而跳表的出现解决了这一难题，为链表的某些节点增加更多的指针，这些指针都指向不同距离的后续节点。**理想的跳表是**：从链表头开始，用多个不同的步长，每隔2^n个节点做一次直接连接，跳表中的每个节点都拥有多个不同步长的指针，在每个节点里，用一个数组Next来记录这些指针。

![image-20240328171542629](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240328171542629.png)

跳表的特性：

- 一个跳表有若干层链表组成
- 每一层链表都是有序的
- 跳表最下面一层的链表包含所有数据
- 如果一个元素出现在某一层，那么该层下面的所有层都必须包含该元素
- 上一层的元素指向下一层的元素必须是相同的
- 头指针head指向最上面一层的第一个元素

**思考题：**

1.二叉搜索树和跳表查询时间与有序数组相同，调整时间为O（log n)而有序数组调整代价是0（n)，是不是意味着会取代有序数组？有序数组的优势是？

我的想法：不能取代数组，因为每种数据结构都有自己的优缺点，应该具体场景采用具体的数据结构。有序数组的优势是：连续的存储空间（节省空间）、适应于随机访问

**整理：**时间复杂度一致，并不代表真实的时间一致，时间复杂度只是量级的。有序数组使用的是一段连续的内存可以支持随机访问，而且由于使用的是连续的内存，可以高效使用**CPU的局部性原理**，可以缓存要访问数据之后的数据，进而**范围查询**更高效。【内存拷贝+内存局部性原理】

- 内存局部性原理：**指在访问存储器时，无论是存取指令还是数据，倾向于集中访问较小的连续区域。**
- 内存拷贝：在进行范围查询时，有时需要将查询结果从原始数据结构中复制到另一个内存位置，可以快速定位和提取所需的数据，提高查询效率。

### 4.哈希表

解决哈希冲突：

**开放寻址法**：使用“线性探查”,在当前位置发现有冲突以后，就顺序去查看数组的下一个位置，看是否空闲，若空闲则插入，否则按顺序看下一个位置，直到找到空闲位置插入。（有很大的弊端，优化方案如下：核心思路都是在发生冲突的情况下，将下一个位置尽可能地岔开，让数据随机分散。然而当插入元素越多，哈希表越满时，性能下降的十分厉害，故不推荐此方法）

- 二次探查：将线性探查的步长从i改为i^2
- 双散列：使用多个Hash函数来求下标值，当第一个hash函数冲突时，就启用第二个，以此类推

**链表法**：   在数组中存储一个链表头。一个key经过Hash函数计算，得到对应的数组下标，就将它存储在该位置所存的链表尾部。【即就是数组+链表的结合，既利用了数组的随机访问特性，又利用了链表的动态修改，同时提供了快速查询和动态修改的能力】

但是当链表很长的时候，遍历代价仍然很大，因此在JDK1.8后，java中的HashMap采用数组＋链表/红黑树的结构。【当链表的长度大于8时，转换为红黑树，当红黑树的节点小于6时，回转为链表】

**哈希表的缺点：**

- 接近O（1）的检索效率是有前提条件的，就是哈希表要足够大和有足够的空闲位置，否则易冲突。**装载因子（默认阈值为0.75）表示哈希表的填充率=哈希表中元素个数/哈希表的长度**。【通常情况下，装载因子越大，哈希表中的冲突越多，查找、插入和删除操作所需的时间会相对增加；而装载因子越小，哈希表中的空间浪费就会增加，但查找、插入和删除操作的性能可能会更好。超过阈值就会进行**扩容**机制，增加哈希表的容量。】
- 尽管使用Hash值直接进行下标访问，带来了O（1）查询效率，但是失去了“有序存储”的这个特点。

![image-20240328175253464](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240328175253464.png)

**思考：**

1.假设一个哈希表是使用开放寻址法实现的，如果我们需要删除其中一个元素，可以直接删除吗？为什么？用链表法会怎么样？

我的想法：用开放寻址法不可以直接删除，若直接删除可能使整个数据处于无序状态（**如果直接将该位置置空，可能会导致后续查找操作出现错误，因为后续查找可能会受到该位置为空的影响而提前结束，造成数据丢失**），再次Hash时，无法找到对应的值，用链表法是可以的，直接修改指针即可。

**整理：**直接删除，探查链条会被终止；局部敏感哈希能在距离信息进行一定的保留。核心考量是冲突元素是否是聚集的。

【C语言和哈希表实现源码：在删除元素的时候，不会真正的删除，会有一个记录状态flag,后续插入新元素还能继续用。否则就会导致每次都有重写申请内存，rehash,计算量太大。】

### 5.位图和布隆过滤器

以注册新用户时查询用户ID为例：申请足够大的数组，让数组的长度超过ID的上限，把数组中所有位置的值都初始化为0，对于存在的用户，直接将用户ID的值作为数组下标，将该位置的值从0设为1即可。

![image-20240328181911380](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240328181911380.png)

在位图的场景下使用多个哈希函数来降低冲突即就是**布隆过滤器**的思想，其最大的特点就是：**对一个对象使用多个哈希函数。**其查询有个特点，就是即使任何两个元素的哈希值不冲突，查询对象的K个位置的值都是1，查询结果为存在，这个结果也可能是错误的，这就是**布隆过滤器的容错率。**

![image-20240328182927327](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240328182927327.png)

使用布隆过滤器可以快速检索是否存在，但是当哈希函数特别多的时候，容错率会增大，因此**也要控制哈希函数的个数**。计算哈希函数个数的数学公式：哈希函数K=（m/n)*In(2).其中m是bit数组长度，n为要存入对象的个数。【实际上，当哈希函数个数为1，且数组长度足够，布隆过滤器就可以退化成一个位图。**位图是只有一个特殊的哈希函数，且没有被压缩长度的布隆过滤器**】

**思考：**1.如果位图中一个元素被删除了，可以将对应bit位置为0.但如果布隆过滤器中一个元素被删除了，直接将对应的K个位置为0，会产生什么样的问题？

我的想法：会导致其他与之相关联的bit数，在查找中不存在。即影响其他元素的判断，增加误判。

**整理：**bitmap是一个集合，每个元素在集合中有一个唯一不冲突的编号（用户自己保证）是双射关系。而布隆过滤器是一个不准确集合，而且是一对多的关系。

对于布隆过滤器无法直接删除，但也有**带引用计数的布隆过滤器**，存的不是0和1，而是一个计数。所有的设计都是一个trade-off(权衡取舍)。

### 6.正排索引和倒排索引

**正排索引**：一个以对象的唯一ID为key的哈希索引结构。

![image-20240329160255420](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329160255420.png)

**倒排索引**：根据具体内容或属性反过来索引文档标题的结构。在倒排索引中，key的集合叫作字典，一个key后面对应的记录集合叫作记录列表。

![image-20240329160305124](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329160305124.png)

创建倒排索引的步骤：

1.给每个文档编号，作为其唯一的标识，并且排好序，然后开始遍历文档。

2.解析当前文档中的每个关键字，生成《关键字，文档ID，关键字位置》这样的数据对。

3.将关键字作为key插入哈希表。如果哈希表中已经有这个key了，就在对应的posting list 后面追加节点，记录该文档ID；若没有，就直接插入该key，并创建posting list 和对应节点。

4.重复第2步和第3步，处理完所有文档，完成倒排索引的创建。

![image-20240329160329986](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329160329986.png)

**如何查询同时含有“极”和“客”字两个key的文档？**

用链表归并：

1.使用指针p1和p2分别指向有序链表A和B的第一个元素。

2.对比p1和p2指向的节点是否相同：

- 两种ID相同，说明该节点为公共元素，直接将该节点加入归并结果。然后，P1和p2要同时后移，指向下一个元素。
- p1元素的ID小于p2元素的ID，p1后移，指向A链表中下一个元素。
- p1元素的ID大于p2元素的ID，p2后移，指向A链表中下一个元素。

多路归并同时查询多个关键字对应的posting list 即可。

![image-20240329160340149](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329160340149.png)

**思考题：**希望查询李白写了哪些诗，即如何在“根据内容查询”的基础上，同时支持“根据作者查询”？

我的思考：在posting list 中再加入author字段

**整理：**可以新建一个倒排索引，分别进行归并排序。（最优）在posting list 的记录中添加域区分。比如用两个比特位，第一个表示是否是作者，第二个表示是否是内容。

### 7.加速倒排索引

跳表法（相互二分查找）、哈希表法、位图法、Roaring BitMap.

**1.跳表法**（**相互二分查找**）：如果A中当前元素小于B中当前元素，就以B中当前元素为key，在A中快速往前跳；如果B中当前元素小于A中当前元素，就以A中当前元素为Key，在B中快速跳。

![image-20240329170521164](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329170521164.png)

对于两个posting list 求交集，可以先使用可变长数组（将链表变为数组），再利用相互二分查找进行归并。并且，由于数组的数据在内存的物理空间中是紧凑的，因此CPU还可以利用内存的局部性原理来提高检索效率。

2.**哈希表加速**：当两个集合要求交集时，如果一个集合特别大，另一个集合相对比较小，就可以用哈希表来存储大集合。可以拿着小集合中的每一个元素去哈希表中对比：如果查找为存在，那查找的元素就是公共元素；否则就放弃。

【注：前提是原始的posting list 必须保留，因为将两个链表都转换为哈希表后，就没有了遍历的能力，所以在哈希表法的最终改造中，一个key后会有两个指针：一个指向posting list ，一个指向哈希表】

![image-20240329170709241](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329170709241.png)

3.**位图法**：求公共元素时，将A、B两个位图中对应位置直接做and运算（0 and 0= 0；0 and 1 = 0；1 and 1 = 1）由于位图的长度是固定的，因此两个位图的合并运算时间代价也是固定的。并且由于CPU执行效率非常快，在位图不是特别长的情况下，位图的检索效率很高。

![image-20240329170658870](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329170658870.png)

- 位图法仅适用于只存储ID的简单的posting list。
- 位图法仅适合posting list中元素稠密的场景。
- 位图法会占用大量空间。

**4.升级版位图_Roaring Bitmap（RBM）（有序数组+位图**）

**设计思想**：其将一个32位的整数分为两部分，一部分是高16位，另一部分是低16位。对于高16位，Roaring Bitmap将它存储到一个有序数组中，这个有序数组就是一个桶；而对于低16位，则存储在2^16的位图中，将相应位置置为1。

![image-20240329170649052](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329170649052.png)

**确认元素是否存在**：通过两次查找就能确认。第一步以高16位在有序数组中二分查找，看对应桶是否存在，若存在，则将桶中的位图取出，拿着低16位在位图中查找，判断相应位置是否为1。【数组二分O(log n)+ 位图O（1）】

**优点：**相比于位图，Roaring Bitmap是通过，将不存在桶的位图空间全部省去这样的方式，来节省存储空间。代价就是将高16位的查找，从O（1）变成了O（log N)。

**优化方案**（与hashmap底层相似）：一个桶对应的存储容器有两种：**数组和位图**

- 在一个桶刚插入数据时，数据量较少，就默认使用数组容器。
- 数据继续插入，当数组容器中元素个数大于4096时，就转换为位图容器。
- 随着数据删除，位图元素少于4096个时，就退化为数组容器。

【确定阈值的默认值通常是一个结合了经验、性能测试和数据特征分析的过程】

![image-20240329170634817](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329170634817.png)

**思考**：在Roaring Bitmap的求交集过程中，有位图和位图求交集、数组和数组求交集、位图和数组求交集。那么它们求交集以后得结果是应该用位图来存储，还是数组来存储？

我的想法：应该具体问题具体分析，在不同的场景下选取最优的存储结构。

**整理：**数组和数组、位图和数组，在交集元素个数较少的情况下可以采用数组来存储。而位图和位图需要进行预判：预判数据大于5096就用位图，反之用数组。

### 8.联合查询的优化方法

调整次序法、快速多路归并法、预先组合法、使用缓存法

1.**调整次序法**：通过从小到大求交集，以及使用集合分配律改写查询，使得检索效率达到最高。（前提：集合的大小要有一定差异）

2.**快速多路归并法**：利用跳表快速跳过多个元素的能力，结合优化的多路归并方案，提升多个posting list 归并性能。

**思路**：将N个链表的当前元素看作一个有序循环数组list[n]。并且，对有序循环数组从小到大依次处理，当有序循环数组中的最小值等于最大值，也就是所有元素都相等时，就找到了公共元素。

3.**预先组合法**：将热门的查询组合提前处理好，作为一个单独的key，保存提前计算好的posting list。

4.**使用缓存法**：将临时的热点查询组合进行结果缓存处理，避免重复查询每次都要重复计算。【内存空间有限，因此需要进行内容替换管理：LRU（最近最少使用替换机制）即当一个对象长期未被访问，那当缓存满时，将会被替换】

一个合适的实现方案是**使用双向链表**：当一个元素被访问时，将它提到链表头。效果是，一个元素若经常被访问，就会经常往前提；若长时间未被访问，渐渐就会排到链表尾部。当缓存满的时候，删除链表尾即可。

**优化**：使用**双向链表+哈希表**实现LRU机制

向链表中插入元素的时候 ，同时向哈希表中插入该元素的key，然后这个key对应的value则是链表中这个节点的地址。因此在查询key的时候，就可以通过哈希表快速查询到链表中的对应节点。

![image-20240329172652750](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240329172652750.png)

### 9.索引和数据分离

数据库中支持多种索引方式：**哈希索引、全文索引、B+树。**

存储在内存和磁盘中数据，检索效率不同的地方：

- **内存**是半导体元件，只要给出了内存地址，就可以直接访问该地址取出数据，具有高效地随机访问特性，因此内存也叫**随机访问器**（RAM）。内存访问速度快，但是价格昂贵，一般计算机内存空间相对较小。【内存位于计算机系统的顶层，是CPU直接能够访问的存储设备】
- **磁盘**是机械文件。磁盘访问数据时，需要等磁盘盘片旋转到磁头下，才能读取相应的数据（访问速度太慢了）。磁盘的最小的读写单位是扇区，操作系统的最小读写单位是快（Block）也叫做簇（Cluster).当需要从磁盘中读取数据时，操作系统会一次将整个块都读出来，因此读写效率更高。【磁盘位于存储层次结构的底层，用于长期存储大量数据和程序】

【重要原则：**对磁盘的访问此处要尽可能地少**】

**拓展**：RAM和ROM的区别

RAM（Random Access Memory)-随机存取存储器：

- 用于临时存储数据和程序，一共CPU进行读取和写入操作。当计算机处于运行状态时，RAM存储着当前正在执行的程序和处理的数据。
- 是易失性存储器，意味着当计算机断电或重启时，RAM中数据会丢失。
- 访问速度快，允许随机读写操作，适用于需要频繁读写和修改数据的。

ROM（Read-Only Memory)-只读存储器：

- 用于存储固化的程序和数据，其中包括计算机的基本启动程序（BIOS或UEFI）和其他固件。
- 是非易失性存储器，即使断电和重启，ROM中的数据也保持不变。
- 访问速度非常慢，而且只能进行读取操作，无法直接对其进行写入和修改。

**线性索引**：用有序数组做索引的办法。

![image-20240330182433036](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330182433036.png)

**树性索引**：二叉检索树更有普适性。

![image-20240330182440647](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330182440647.png)

**B+树**给出了将树形索引的所有节点都存放在磁盘上的高效检索方法

![image-20240330182452245](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330182452245.png)

【B+树的关键设计：就是让一个节点的大小等于一个块的大小。节点内存储的数据，不是一个元素，而是一个可以装m个元素的有序数组】

此外，B+树还将同一层的所有节点串成了**有序的双向链表**，同时具有良好的范围查询能力和灵活调整的能力。【B+树是一颗**完全平衡的M阶多叉树**。所谓M阶，指的是每个节点最多有M个子节点，并且每个子节点里都存了一个紧凑的可包含m个元素的数组。**B+树的内部节点和叶子结点的区分，就是数据和索引分离的一次实践**】

B+树的动态调整：通过**分裂**进行。**分裂的逻辑就是生成一个新节点，并将数据在两个节点中平分**。

![image-20240330182511794](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330182511794.png)

![image-20240330182521540](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330182521540.png)

![image-20240330182530757](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330182530757.png)

**拓展**：完全平衡的M阶多叉树：

- 定义：其中每个非叶节点最多**有M个子节点**，并且所有叶节点都位于树的相同深度，使得从根节点到任何一个叶节点的路径长度都相同。这样的树在每一层上都是“满”的，除了最后一层外，最后一层的节点尽可能地从左到右填充。
- **关键字**是M阶多叉树中存储的数据项，每个节点可以包含一个或多个关键字。通常情况下，关键字按照一定的顺序组织，以便进行搜索、插入和删除等操作。
- **失败节点**指的是在对M阶多叉树执行插入或删除操作时，由于某种原因导致操作无法成功完成而产生的节点。

**思考题**：B+树有一个很大的优势，就是适合范围查询。如果要检索值在X到Y之间的所有元素，该如何操作？

我的想法：通过B+树结构，首先对X进行二分查找，再向后遍历到Y。

**整理**：先找到X所在的叶子节点，叶子结点数据二分查找找到X，然后向右遍历直到不在X和Y区间内{**二分查找+遍历**}。原因是：涉及磁盘io（input/output)顺序io的速度永远大于随机IO。

### **10.LSM树（Log Structed Merge Trees)**

B+树的数据都存储在叶子节点中，而叶子结点一般存储在磁盘中。因此，每次插入的新数据都需要随机写入磁盘，但是随机写入的性能非常差。**Lsm树是近年来许多火热的NoSQL数据库中使用的检索技术。**

利用批量写入代替多次随机写入：当数据写入时，延迟写磁盘，将数据先存放在内存中的树里，进行常规的存储和查询。当内存中的树持续变大到阈值时，再批量地以块为单位写入磁盘中。【LSM树，一般由两颗树组成，一颗存储在**内存中较小的C0树**，另一棵存储在**磁盘中较大的C1树**。】

![image-20240330185916278](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330185916278.png)

C1树有个特点：所有的叶子结点都是满的，因为C1树不需要支持随机写入，完全可以等内存中的数据写满一个叶子节点后，再批量写入磁盘。

为了保证内存中的数据在系统崩溃后能恢复，**工业界采用WAL（Write Ahead Log,预写日志技术）**将数据第一时间高效写入磁盘进行备份。

![image-20240330185904630](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330185904630.png)

将内存数据与磁盘数据合并采用的是**滚动合并**。

![image-20240330185856832](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330185856832.png)

![image-20240330185848390](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330185848390.png)

**总结**：LSM树的三个特点：

- 将索引分为内存和磁盘两部分，并在内存达到阈值时启动树合并（Merge Trees)
- 用批量写入代替随机写入，并且用预写日志WAL技术保证内存数据，在系统崩溃后可以被恢复。
- 数据采取类似日志追加写的方式写入（Log Structured)磁盘，以顺序写的方式提供写入效率。

**思考**：对于纯内存操作，其他类树结构会更合适，你会采用怎样的结构作为C0树？

我的想法：对于C0树的设计应该因地制宜，采用合适的数据结构去适应于不同的场景。（跳表、哈希表、红黑树）

**整理：**使用什么结构，取决于系统需要提供什么样的功能，如果系统需要提供高效的查询不需要范围查询就用hashmap，如果需要范围查询那么平衡树或者跳表合适。

![image-20240330185837721](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240330185837721.png)

【SSD（Solid-State Drive），即固态硬盘，是一种使用固态存储器作为数据存储介质的存储设备。是以页作为读写单位，以块作为垃圾回收单位，因此批量写的性能依然大于随机写！SSD的性能和内存相比依然有差距，因此，先在内存里处理好，再批量写入SSD依然是高效的】

### 11.对万亿级别的网页生成倒排索引

对于大规模的倒排索引：内存的检索效率比磁盘高很多，因此尽可能的将数据加载到内存中。

倒排索引：**key集合的词典** 和 **key对应的文档列表** 组成，当有查询发生时，通过检索内存中的哈希表，就能找到对应的key，然后再将磁盘中key对应的posting list 读到内存中进行处理。

![image-20240401225313694](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225313694.png)

检索过程：①使用B+树或类似的技术，查询到对应词典中的关键字。②将这个关键字对应的posting list 读出，在内存中进行处理。

![image-20240401225325526](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225325526.png)

两个重要的设计思想：

- **尽可能地将数据加载到内存中**：因为内存的检索效率大大高于磁盘。（索引压缩）如Lucene就使用了类似于前缀树的技术FST，来对词典进行前后缀的压缩，使得字典可以加载到内存中。
- **将大数据集合拆成多个小数据集合来处理**：分布式系统的核心思想。

**思考：**词典如果加载到内存中，就会大幅提升检索效率。在哈希表过大无法存入内存的情况下，是否还有可能使用其他占用内存空间更小的数据机构，将词典完全加载在内存中？有序数组或二叉树可以吗？

我的想法：有可能，可以使用两个数组，对应哈希表的key和value

**整理**：①使用数组存每个词项，需要解决每个词项长度不同的问题，一个思路就是使用最长的词项作为数组每个元素的大小，这样就可以用数组存储和查找。②第一种方法太浪费空间了，因此改进方案：另外开一个char数组，将所有字符串挨个紧凑存入；然后索引数组每个元素都是int 32类型，指向char数组中对应词项的初始位置。【会发现数组中很多重复项，压缩重复字符的前缀树就出来了】

### 12.不同规模的倒排索引

生成大于内存容量的倒排索引：

1.给每个文档编号，作为它们的唯一标识，并且排好序。

2.顺序扫描每一个文档，将当前扫描文档中的所有内容生成《关键字，文档ID，关键字位置》数据对，并将所有的数据对，都以关键字为key存入倒排表。

3.重复第2步，直到处理完所有文档。

![image-20240401225423005](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225423005.png)

完整的倒排索引表结构：

![image-20240401225443391](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225443391.png)

生成工业级的倒排索引：

1.将大规模文档均匀**划分为多个小的文档**集合，并按照之前的方法，为每个小的文档集合在内存中生成倒排索引。

2.将内存中的倒排索引存入磁盘，生成**临时倒排文件**（要根据关键词排好序）。临时文件中不需要存储关键词的编号，因为每个临时文件的编号都是局部的，并不是全局唯一的，故不需要保存。

![image-20240401225408010](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225408010.png)

3.依次处理每个临时文件，等文档全部处理完，就得到了磁盘上的多个临时文件。多个临时文件的合并，就采用**多路归并**技术。【先将所有临时文件记录的关键词取出，关键词相同，就将对应的posting list 读出，合并】

![image-20240401225357225](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225357225.png)

工业界更新内存中的索引：

使用**Double Buffer(双缓冲机制**)：就是在内存里同时保存两份一样的索引，一个是索引A，一个是索引B。会使用一个指针p指向索引A，表示索引A是当前可访问的索引。那么用户在访问时就会通过指针p去访问索引A。若需要更新，指更新索引B即可。AB之间不存在读写竞争关系。更新完B后，将指针B通过原子操作从A直接切换到B上，此时把B当作“只读索引”,然后更新索引A。

![image-20240401225537875](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225537875.png)

**全量索引结合增量索引**：系统会周期性地处理全部的数据，生成一份完整的索引，不可以被实时修改，这就是**全量索引**；会新接收一个数据库单独建立一个可以存在内存中的倒排索引，就是**增量索引**。查询的时候，同时查询二者，将合并的结构作为总结果输出。

对于**删除操作则需要增加一个删除列表**，将被删除的数据记录在列表中，检索时，将全量倒排表和增量倒排表和删除列表作对比。若结果数据在删除列表中，则证明该数据无效，直接删除。

![image-20240401225618504](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225618504.png)

增量索引空间的持续增长处理办法：

完全重建法：在增量索引写满内存之前，完全重建依次全量索引，然后将系统查询切换到新的全量索引中。操作简单、效率不高

再合并法：直接归并全量索引和增量索引，生成一个新的全量索引，就避免了从头处理所有文件的开销，效率会稍微高点。

![image-20240401225714349](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225714349.png)

滚动合并法：先生成多个不同层级的索引，然后逐层合并。【一个检索系统在磁盘中保存了全量索引、周级索引、天级索引；查询是并行的，一般的系统实现是：增量索引+天极索引+全量索引，三个索引并行检索，再合并结果】

![image-20240401225709491](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225709491.png)

**思考：**为什么在增量索引的方案中，对于删除数据，无法像LSM树直接删除，而是需要设置一个删除列表？

**整理**：倒排索引和kv不同，posting list元素很多，每个元素都标记代价很大。而且一个文档可能会影响多个key，因此每个文档都修改标记，读写操作会很频繁，加锁性能下降。

### 13.利用分布式技术

**分布式技术的特点**：分布式技术就是将大任务分解成多个子任务，使用多台服务器共同承担任务，让整体系统的服务能力相比于单机系统得到了大幅度提升。

**分发服务器**：只负责任务分发    **索引服务器**：真正执行检索任务

当分发服务器接到请求时，它会负责负载均衡机制，将当前查询请求发给某台较为空闲的索引服务器进行查询。具体的检索工作由该台索引服务器独立完成，并返回结果。

![image-20240401225914638](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225914638.png)

【索引拆分的好处：一方面能将更多的索引数据加载到内存中，降低磁盘访问数据，使得检索效率能得到大幅度提升；另一方面是基于文档划分，能将一个查询请求复制多份，由多台索引服务器并行完成，单次检索的时间也会缩短】

**业务拆分**：（图书索引）耦合性太强，需要灵活调整方案。

**关键词拆分**：将词典划分为多个分片，分别加载到不同的索引服务器上。

![image-20240401230011306](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401230011306.png)



![image-20240401225947185](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225947185.png)

**基于文档拆分**：将大规模文档集合**随机**划分为多个小文档集合分别处理。

![image-20240401225926885](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225926885.png)

![image-20240401230028444](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401230028444.png)

- 分发服务器接受查询请求，将请求发送给所有不同索引分片的索引服务器。
- 每台索引服务器根据自己加载的索引分片进行检索，将查询结果返回分发服务器。
- 分发服务器将所有返回的结果进行合并处理，再返回最终结果。

**水平拆分**：根据处理对象将倒排索引进行拆分，每个索引分片都可能有完整的词典，但posting list 不完整。

**垂直拆分**：根据倒排索引中的关键词进行拆分，每个索引分片的词典都不完整，但是词典中的关键词对应的posting list是完整的。

![image-20240401225936269](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401225936269.png)

**思考**：为什么说基于文档拆分的方案会比基于关键词的拆分方案更好维护？

**整理**：基于文档或关键词拆分，类似于数据库分表。基于文档操作的好处是在于分担网络和IO的压力。

### 14.精准Top K 的检索

三种打分方法：经典算法TF-IDF、概率模型BM25算法、机器学习打分。

**1.经典算法TF-IDF**：它能很好的表示一个词在一个文档中的权重。TF-IDF算法的公式是：**相关性 = TF * IDF**。其中，**TF是词频**，**IDF是逆文档频率**。

- **词频**：一个词项在文档中出现的次数。
- **文档频率**：这个词项出现在多少个文档中。
- **逆文档频率**:对文档频率取倒数，它的值越大，这个词的区分度越大。

![image-20240402154018352](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402154018352.png)

**2.BM25算法（Best Matching)**：是TF-IDF的一种升级。它的设计思想是：它认为词频和相关性的关系并不是线性的。即随着词频的增加，相关性的增加会越来越不明显，并且还会有个阈值上限。当词频达到阈值以后，相关性就不会再增长了。

![image-20240402154525137](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402154525137.png)

![image-20240402154532891](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402154532891.png)

![image-20240402154653220](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402154653220.png)

![image-20240402154703105](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402154703105.png)

![image-20240402154811969](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402154811969.png)

**3.机器学习：**把不同的打分因子进行加权求和。比如，有n个打分因子，分别为X1到Xn，而每个因子都有不同的权重，记为w1-wn,打分公式：

​                     Score = w1*x1+w2*x2+w3*x3+....+wn*xn

一般来说会使用Sigmoid函数（特点：**X值越大，Y值越接近1；X值越小，Y值越接近0。并且，X值在中间一段范围内，相关性的变化最明显，而在两端会发生边际效应递减的现象**）对Score进行处理，让他处于（0,1）范围内。

![image-20240402155609228](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402155609228.png)

利用机器学习可以更大规模地引入更多的打分因子，并且可以自动学习出各个打分因子的权重。**完成打分阶段后，排序阶段要重视效率**。对应精准Top K 检索，可以使用**堆排序**来代替全排序，只返回最重要的K个结果。时间代价是：O（n) + O(k log n).

**思考：**

1.在精准Top K检索的过程中，哪部分最耗时？

2.机器学习的优点在哪？

我的想法：精准检索过程中，打分最耗时，因为无论采用哪种算法都需要处理所有的数据；机器学习的优点在于更加精准的打分，它会通过不断训练，得出一个近乎更好的模型。

**整理：**最耗时的步骤是打分，尤其引入机器学习计算量大大超过排序。机器学习的关键就是寻找因子以及学习权重的过程。

1.对于文档DF，会随着文档的增加而变化。因此需要更新，在倒排索引中，由于IDF是和key存在一起的，因此，可以在文档变化时，对增量倒排索引的key中的IDF值进行更新。【注：若基于文档水平拆分，那么增量索引只会在一个分片中生效。持续久了，IDF值会不准确，相关计算精度会下降，因此需要周期性的重构全量索引。】

2.机器学习也需要频繁更新。一般是每天更新，有点系统为了及时更新，还会使用在线学习进行实时更新。

### 15.非精准 Top K 的检索

非精准 Top K 检索的思路：**高质量的检索结果并不一定要非常精准，只需要保证质量足够高的结果，被包含在最终的Top K 个结果中就够了。**

**降低打分计算复杂度的核心思路**：尽可能地将计算放到离线环节，而不是在线环节。

![image-20240402163359658](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402163359658.png)

- 根据**静态质量**得分排序截断：打分计算仅和结果自身质量有关。

- 根据**胜者表+词频**得分排序截断：同时结合词频和静态质量得分进行排序（权重 = 词频 + 静态质量得分），这样就同时考虑了相关性和结果质量两个维度。然后对应每个posting list 提前截断r个结果，再按文档ID排序即可。【胜者表：根据某种权重将posting list 中的元素进行排序，并提前截取R个最优结果的方案。】

- 使用**分层索引**（特殊的索引拆分）：可以同时考虑相关性和结果质量，用离线计算的方式先给所有文档完成打分，然后将得分最高的M个文档作为高分文档，单独建立一个高质量索引，其他的文档则作为低质量索引。高质量和低质量索引的posting list 都可以根据静态质量得分来排序，以方便检索的时候能快速截断。

  ![image-20240402163347052](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402163347052.png)

非精准Top K检索的思想可以拓展应用到在线环节。在倒排索引检索结束后，精准打分排序前，插入一个“非精准打分”环节。【此外，非精准打分和精准打分是相对的】

![image-20240402163331993](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402163331993.png)

**思考:**

1.在分层索引中，posting list 中的文档为什么还要根据静态质量得分排序？

2.对于非精准检索的场景有哪些？

**整理：**静态质量得分的非精准打分和精准打分对象是不同的；它的非精准打分因为是离线打分，针对的是文档进行打分，该文档的所有关键词的分都一样；它的精准打分针对某个关键词和文档的相关性进行打分。

### 16.利用空间检索技术查询附近的人

非精准检索思路：只需要查询自己所在城市的人，然后计算出彼此的距离即可。在同一个城市内也可以优先查找同一个区用户，再次缩小查询范围。

![image-20240402163805032](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402163805032.png)

- 区域有层次关系：如果两个区域的前缀和是相同的，就说明属于同一个大区域。
- 区域编码带有分割意义：奇数位的编号代表了垂直切分，偶数位的编号代表了水平切分，方便区域编码的计算（奇偶数位从右边以第0位开始数起）

区域编码能将二维空间的两个维度用一维编码表示。

![image-20240402170548940](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402170548940.png)

如果要降低计算量，可以将区域划分的粒度提高一个量级。这样，在查询半径不变的情况下，需要检索的用户数量就会更少。

![image-20240402170540396](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402170540396.png)

快速寻找这些区域的编码：通过分解出当前区域的水平编码和垂直编码，对对应的编码进行加1或者减1的操作，就能得到不同方向上邻接的8个区域的编码。

![image-20240402170638240](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402170638240.png)

Geohash编码：将经纬度坐标转换为字符串的编码方式。

![image-20240402170533424](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402170533424.png)

![image-20240402170520470](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402170520470.png)

### 17.用四叉树快速寻找最近的K个元素

**四叉树**：四叉树的树根节点代表了整个空间，每个节点的四个分叉分别表示四个子空间。其中，树根和中间节点不存储数据，只记录分叉指针，而数据只记录在最小的区域，也就是叶子节点上。

**满四叉树**：从根节点开始，不停四分，直到每个分支的叶子结点都是最小粒度区域。这样构建出来的四叉树，每个节点都有4个子节点。

![image-20240403173300958](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173300958.png)

利用非满四叉树优化空间：**使用动态节点分裂的非满四叉树**（数据稀疏）

![image-20240403173310309](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173310309.png)

对于字符串的检索，有种专门的数据结构：**前缀树（Trie树）**

它是一种逐层划分检索空间的数据结构，它的根节点代表了整个检索空间，然后每个中间节点和叶子节点都只存储一个字符，代表一个分支。这样，从根节点到叶子节点的路径连起来，就是一个完整的字符串。【使用GeoHash编码来表示区域时，可以建立一个前缀树来进行索引，前缀树的每个节点最多会有32个节点】

![image-20240403173319794](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173319794.png)

利用树形结构来划分空间提高检索效率的方案应用广泛，对于高纬度空间，还可以使用**K-d树(K-Dimensional Tree)**来检索。K-d树是一种更通用的，对任意维度都可以使用的方案。它在划分子空间的时候，并不是直接将整个空间划分为2 ^k个子空间，而是**会选出最有区分度的一个维度，将该维度的空间进行二分，然后对划分出的子空间再进行同样的二分处理，实际是二叉树**。而且，由于分支数和维度K的具体值无关，因此具有更好的通用性。

**思考**：在非满二叉树的分裂过程中，为什么节点不一定会生成4个叶子节点？

我的思考：因为本身存的数据比较稀疏，4个节点过于浪费空间。

**整理：**极端情况下，所有插入的数据都属于一个小区域，那么根节点就不需要分裂成其他分叉。（其实就是数据分布造成的）

### 18.局部敏感哈希的方法过滤相似文章

**向量空间模型**：计算两篇文章的相似性；就是将所有文档中出现过的所有关键字都提取出来，如果一共有N个关键词，那每个关键词就是一个维度，这就组成了一个n维的向量空间。

![image-20240403173327141](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173327141.png)

对于高维空间的近邻检索问题，可以使用**近似最近邻检索**。

工业界设计了一种哈希函数，它可以让相似的数据通过哈希计算后，生成的哈希值是相近的（甚至相等的），这就是**局部敏感哈希**（Locality-Sentitive Hashing）

![image-20240403173335353](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173335353.png)



**对于高位空间，构造局部敏感哈希函数的方案**：随机生成n个超平面，每个超平面都将高维空间划分为两部分。位于超平面上面的点哈希为1，反之为0。由于有N个超平面，因此一个点会被判断N次，生成一个N位的包含0和1的序列，它就是这个点的哈希值。【在利用局部哈希值来判断文章相似性时，会以表示比特位差异数的**海明距离（Hamming Distance)**为标准】

![image-20240403173341995](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173341995.png)

**SimHash:**使用一个普通哈希函数代替了N次随机超平面划分，并且这个普通哈希函数的作用对象也不是文档，而是文档中的每一个关键词。

步骤：①文档分词，带权重；②生成哈希值；③将0改为-1；④乘上词权重；⑤按位相加；⑥编码转化为0和1

![image-20240403173348658](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173348658.png)

对局部敏感哈希值进行相似检索步骤：

1. 计算出待查询文档的SimHash值
2. 以该SimHash值中每个比特位的值作为key，去倒排索引中查询，将相同位置具有相同值的文档都召回
3. 合并这些文档，并一一判断它们和要查询的文档之间的海明距离是否在3以内，留下满足条件的。

**抽屉原理**：Google会将哈希值平均切为4段，如果两个哈希值的比特位差异不超过3个，那这三个差异的比特位最多出现在3个段中，也就是说至少有一个段的比特位是完全相同的。

![image-20240403173359448](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173359448.png)

【通过使用SimHash函数和分段检索（抽屉原理）使得Google能在百亿级别的网站快速完成过滤相似网页的功能，从而保证了搜索结果的质量】

![image-20240403173405389](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403173405389.png)

**思考：**

1.对于SimHash，如果将海明距离在4以内的文章都定义为相似的，那应该将哈希值分为几段进行索引和查询呢？

2.SimHash的算法能否应用到文章以外的其他对象？

**整理：**

1. 对于SimHash，如果将海明距离在4以内的文章定义为相似的，一般会将哈希值分为16段进行索引和查询。这是因为SimHash使用64位哈希值，海明距离在4以内的哈希值有16位不同，因此将哈希值分为16段可以有效地提高查询效率。当然，具体分段的策略也可以根据实际情况进行调整。
2. SimHash算法通常用于文本相似度比较，但也可以应用到除文章以外的其他对象，只要这些对象可以通过某种方式表示为二进制哈希值。例如，可以将图片、音频、视频等对象转换为哈希值，并使用SimHash算法进行相似度比较。在这种情况下，需要选择合适的哈希函数来将不同类型的对象转换为哈希值，并根据具体的应用场景进行调整和优化

### 19.近似最近邻检索—乘积量化

使用**聚类算法**来划分空间，和简单的局部敏感哈希算法相比，聚类算法能将空间中的点更灵活的划分为多个类，并且保留了向量的高纬度，可以更准确地计算向量间的距离。

![image-20240403181059905](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181059905.png)

K-Means聚类算法：将所有的点划分为K个类，每个类都有一个类中心向量。在构建聚类的时候，希望每个类内的点都是紧密靠近类中心的。K-Means的聚类算法优化的目标——**类内的点到类中心的距离均值总和最短**。

![image-20240403181111963](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181111963.png)

为了更好的将向量加载到内存中，需要**压缩向量**的表示。想要压缩向量，会使用**向量量化（Vector Quantization)**，其中，最常用的就是**乘积量化（Product Quantization).**

![image-20240403181125289](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181125289.png)

**量化：将一个空间划分为多个区域，然后为每个区域编码标识。**

**乘积：指的是高纬度空间可以看作是由多个低纬度空间相乘得到的**。

![image-20240403181202148](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181202148.png)

让每段子向量都根据聚类算法找到所属的聚类，然后用它所属聚类的ID来表示这段子向量。

![image-20240403181218753](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181218753.png)

计算查询向量和压缩样本向量的距离：设计3个主要向量（样本向量、查询向量、聚类中心向量）

![image-20240403181250875](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181250875.png)

![image-20240403181425585](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181425585.png)

**倒排向量索引乘积化的步骤：**

![image-20240403181453680](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181453680.png)

**思考**：为什么使用聚类中心向量来代表聚类中的样本向量，就可以节省存储空间？

**整理：**压缩的根源，在于可以使用1个类的中心向量来代替类内所有的N个样本向量。

![image-20240403181301072](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181301072.png)

### 20.四种设计思想

索引与数据分离、减少磁盘IO、读写分离、分层处理

**索引与数据分离好处**：

- 节约存储空间，不需要在posting list 中重复记录唐诗的内容。
- 减少检索过程中的复制代价。
- 保持索引的简单有效，可使用更多的优化手段加速检索过程。

牢记奥卡姆剃刀原理**“如无必要，勿增实体”**

MySql中的B+树有两种，一种是MyLSAM引擎，另一种是InnoDB引擎。它们的核心区别就是，数据和索引是否分离。

在MyISAM引擎中，B+树的叶子结点仅存储了数据的位置指针，这是一种索引分离的设计方案，叫作非聚集索引。若要保证MyIASM的数据一致性，需要在表级别上进行加锁处理。

![image-20240403181330976](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181330976.png)

在InnoDB中，B+树的叶子节点直接存储了具体的数据，这是一种索引和数据一体的方案，叫作聚集索引。由于数据直接就存在索引的叶子结点中，因此InnoDB不需要给全表加锁来保证一致性，只需要支持行级的锁。

![image-20240403181337044](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181337044.png)

尽可能地减少磁盘IO，是保证系统具有高性能的核心设计思路。减少磁盘IO的一种常见设计**，是将频繁读取的数据加载到内存中**。

在读操作高于写操作的应用场景中，使用读写分离的设计思想，可以大幅度提升系统的性能。

![image-20240403181348804](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181348804.png)

![image-20240403181703504](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181703504.png)

![image-20240403181358167](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403181358167.png)

### 21.LevelDB的架构设计

LevelDB是基**于LSM树【“Interval Skip List Merge Tree”，即区间跳跃表合并树】优化而来**的存储系统，使用**跳表**代替B+树来实现C0树。LevelDB做了**读写分离设计**，将内存中的数据分为两块，一块叫作**Mem Table** ,它是**可读可写**的，另一块叫作 **Immutable MemTable**，是**只读的**。这两块数据的数据结构完全一样，**都是跳表**。

【小剧场：ISM树和B+树的区别】

- **B+树**：随机读很多，写很少的场景，因为B+树能快速二分找到任何数据，并且磁盘IO很少。【反之ISM树，大量的随机读，它无法在内存中命中，因此会去读磁盘，并且是一层层多次读，会带来严重的读放大效应】
- **ISM树：**适合大量写操作，日志系统和监控系统这类大量生成写入数据的应用会采用ISM树【因为B+树每次写入都需要修改叶子结点，这会带来大量的磁盘IO】

当MemTable的存储数据达到上限时，直接将它切换为只读的Immutable MemTable，然后重新生成一个新的Mem Table,来支持新数据的写入和查询。将内存索引存储到磁盘的问题，就变成了将 Immutable MemTable 写入磁盘的问题。而且，由于 Immutable MemTable 是只读的，因此，它不需要加锁就可以高效地写入磁盘中。

LevelDB采用了**延迟合并的设计来优化合并**，先将Immutable MemTable顺序快速写入磁盘，直接变成一个SSTable(Sorted String Table)文件，之后再对这些SSTable文件进行合并。

**检索过程**：先在SSTable中查找，如果查找不到再去Immutable MemTable中查找。如果Immutable MemTable也查询不到，就会到磁盘中查找。

![image-20240406163805467](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240406163805467.png)

**SSTable的分层管理：**从Immutable MemTable转成的SSTable会被放在Level 0层。Level 0 层最多可以放4个SSTable文件，满了之后，就要进行多路归并，生成新的有序的多个SSTable文件，这一层有序的SSTable文件就是Leve 1层。当Level 1 层的SSTable 文件总量达到上限之后（默认是10M），就需要选择一个SSTable 的文件，将它并入下一层【为保证一层中每个SSTable文件都有机会并入下一层，选择SSTable文件的逻辑就是轮流选择】**下一层会将容量上限翻10倍**。

![image-20240406164450332](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240406164450332.png)

尽管LevelDB通过限制每层的文件总容量大小，能保证多路归并时，会有一个开销上校，但层数越大，容量上限就越大，发生在下层的多路归并依然会造成大量的磁盘IO开销。**LevelDB 是通过加入一个限制条件解决的**。在多路归并生成第 n 层的SSTable 文件时，LevelDB 会判断生成的 SSTable 和第 n+1 层的重合覆盖度，如果重合覆盖度超过了 10 个文件，就结束这个 SSTable 的生成，继续生成下一个 SSTable 文件。

**LevelDB 就保证了第 n 层的任何一个 SSTable 要和第 n+1 层做多路归并时，最多不会有超过 10 个 SSTable 参与，从而保证了归并性能**。

![image-20240406165017310](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240406165017310.png)

**查询指定元素：**LevelDB使用索引与数据分离的设计思想，将SSTable 分为**数据存储区**和**数据索引区**，在读取SSTable 文件时，只需要先将数据索引区中相关的数据读入内存就好了，可以减少磁盘IO次数。

![image-20240406165321097](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240406165321097.png)

需要快速确定SSTable是否包含查询的元素，可以使用**BloomFilter进行高效检索。**从数据索引区中读出BloomFilter的数据，若查询结果存在，就继续进行精确查找，否则跳过这个SSTable文件。

在进行精确查找时，将数据索引区中的index Block读出，Index Block中的每条记录都记录了每个Data Block 的最小分割Key,起始位置，还有block大小。由于所有的记录都是根据key排好序的，因此进行二分查找即可。

针对两次读磁盘操作，LevelDB分别设计了 **table cache**和**block cache** 两个缓存。其中，block cache是配置可选的，它是将最近使用的Data Block 加载在内存中。而table cache则是将最近使用的SSTable的Index Block加载在内存中。两个缓存都使用了**LRU机制进行替换管理**。【想读取一个 SSTable 的 Index Block 时，首先要去 table cache 中查找。如果查到了，就可以避免一次磁盘操作，从而提高检索效率。同理，如果接下来要读取对应的Data Block 数据，那么我们也先去 block cache 中查找。如果未命中，才会去真正读磁盘】

**思考：**

1.当我们查询一个 key 时，为什么在某一层的 SSTable 中查到了以后，就可以直接返回，不用再去下一层查找了呢？如果下一层也有 SSTable 存储了这个 key 呢？

2.为什么从 Level 1 层开始，我们是限制 SSTable 的总容量大小，而不是像在 Level 0 层一样限制 SSTable 的数量？（提示：SSTable 的生成过程会受到约束，无法保证每一个SSTable 文件的大小）

**整理：**

1.因为 LevelDB 天然的具有缓存的特性，最经常使用的最新的数据离用户最近，所有在上层找到数据就不会在向下找了

2: 如果规定生成文件的个数，那么有可能当前层和下一层的存储大小相近了，起不到分层的作用了【由于在生成sstable文件时，有这么一个限制:新生成的sstable文件不能和下层的sstable覆盖度超过十个，因此可能会生成多个小的sstable文件。那如果只看文件数的话，多个小的sstable文件可能容量和下一层差不多，这样就没有了分层的作用了】

### 22.搜索引擎是如何工作的？

搜索引擎设计领域：网页抓取、文本分析、检索模型、索引技术、链接分析、反作弊、云存储和云计算。从功能结构上，把搜索引擎的核心系统分为三部分，分别是**爬虫系统**、**索引系统**（拆分、构建、更新）和**检索系统**。

![image-20240406172250647](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240406172250647.png)

**搜索引擎最大的特点，就是它有一个很强的检索约束条件，那就是用户输入的查询词。可以说，查询词是搜索引擎进行检索的最核心的信息。**

在查询分析的过程中，主要会对搜索词进行**分****词粒度分析**、**词的属性分析**、**用户需求分析等工作。其中，分词粒度分析直接关系到以什么 key 去倒排索引中检索，而属性分析和需求分析则可以在打分排序时，有更多的因子可以考虑。因此，**分词粒度分析是查询分析的基础**。

![image-20240406172918467](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240406172918467.png)

查找纠错的过程一般分为三个步骤：**错误判断**、**候选召回**和**打分排序**

![image-20240406173059752](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240406173059752.png)

**位置信息索引法**：通过两个关键词的位置关系来判断该文档和检索词的相关性。位置越远，相关性就越小，如果位置直接邻接在一起，相关性就最高。如果是关键词联合查询，会将同时包含所有关键词的最小片段称为**最小窗口**，然后通过衡量查询结果中最小窗口的长度，来判断多个关键词是否接近。

整理：

1.page rank算法在搜索引擎中的具体应用？

通过分析不同网页之间的相互链接关系，来判断网页质量。PageRank是一种链接分析算法，它通过对超链接集合中的元素用数字进行权重赋值，实现“衡量集合范围内某一元素的相关重要性”的目的。该算法可以应用于任何**含有元素之间相互引用的情况**的集合实体。

- 1.在进行索引分层时，高质量网页和普通质量网页需要区分，这时候page rank质量分就是一个很重要的参考。
- 2.打分排序阶段，page rank质量分也是很重要的因子。
- 3.在进行锚文本分析时，高质量网页出来的锚文本更重要。
- 4.在爬虫抓取网页时，可以优先抓取高质量的网页链接出来的网页。

### 23.广告引擎工作原理

**搜索广告：**用户主动输入关键词以后，搜索引擎在返回结果中展示的相关广告

**展示广告：**在搜索引擎之外的网站或App中，用户在浏览页面的情况，被动看到广告。

![image-20240407193141057](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193141057.png)

广告引擎处理一个广告请求的过程，本质上就是根据用户的广告请求信息，找出标签匹配的广告设置，并将广告进行排序返回的过程。

**标签检索：合理使用标签过滤和划分索引空间**（树形检索+倒排索引+结果过滤）

![image-20240407193200428](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193200428.png)

1.广告作为树形结构的节点分叉进行分流

2.作为倒排索引的key

3.在遍历候选结果时作为候选条件

![image-20240407193151792](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193151792.png)

**向量检索：提供只能匹配能力**（聚类+倒排索引+乘积量化）

![image-20240407193110068](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193110068.png)

**打分排序：用非精准分结合深度学习模型的精准打分**（召回）

![image-20240407193120206](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193120206.png)

**索引极简：在索引构建环节缩小检索空间**（全量索引+增量索引）

![image-20240407193127460](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193127460.png)

### 24.引擎中的个性化召回

相比于搜索引擎和广告引擎，**推荐引擎具有更灵活的检索能力**，也就是可以使用更灵活的检索技术，来进行文章的召回服务。

![image-20240407193050924](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193050924.png)

**基于内容的召回：根据文章的内容，判断这篇文章是否符合用户的喜好**

本质上是基于用户画像和文章画像进行匹配召回，标签检索+向量检索

![image-20240407193043828](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193043828.png)

**基于协同过滤的召回：并不依赖于内容本身进行推荐，而是基于大众用户和这篇文章的互动关系来进行推荐。**（检索-排序）

1.基于数据统计的Memory-based协同过滤（基于邻域算法）

- 基于用户的协同过滤
- 基于物品的协同过滤

2.升级版的基于模型的Model-based的协同过滤算法

**如何对多种召回方案进行选择和排序**：混合推荐法

![image-20240407193035126](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193035126.png)

首先，每一个召回通路都会使用自己的非精准打分算法，截取千级别之内的候选集。然后，推荐引擎会合并这多个召回通路截取的几千个结果，也就是使用简单的机器学习模型进行非精准打分，选出最好的上百个结果。最后，搜索引擎会使用精准的深度学习模型，选出的几十个结果返回给用户。这就是最终推荐结果。

![image-20240407193029814](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240407193029814.png)

### 25.结语

记于2024/4/7

​    此书完美落幕。感谢陈东老师的倾情讲解，感谢烤肉的友情推荐，感谢自己的热情阅读。从序言的“道阻且长、行则将至”开始，就喜欢上来这本书，由浅入深的讲解，层层递进，恰到好处。使我之前很迷茫的点串联到了一起，比如参加建模大赛时了解到的聚类分析、深度学习等，如今再一次深入了解。再比如各种数据结构，我总以为它们是独立存在的，殊不知，它们竟是为了根据人们的需求不断优化而来的，一瞬间茅塞大开。未来的路也许会很长，但我总会记得序言的那几句：“**多思考，多提问，善用“理解记忆法”**、”**建立自己的知识体系**“、”**有耐心、反复学、多交流**“。路很长，又怎样？走下去，总归有路！
